{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "2024-04-19 19:38:30.086547: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    }
   ],
   "source": [
    "# Import packages and functions for part 1\n",
    "import pandas as pd\n",
    "from ckiptagger import WS, POS, NER\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from scipy import sparse\n",
    "\n",
    "# 先把我們需要的函數載入\n",
    "ws = WS(\"./data_ckip\") # 斷詞\n",
    "pos = POS(\"./data_ckip\") # 詞性標注\n",
    "ner = NER(\"./data_ckip\") # 命名實體識別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(sentence_ws, sentence_pos):\n",
    "    '''\n",
    "    - sentence_ws: 經過斷詞的句子\n",
    "    - sentence_pos: 經過詞性標注的句子\n",
    "    - 留下特定的詞性（名詞、動詞、形容詞）、排除一個字的詞、專有名詞\n",
    "    '''\n",
    "    cleaned = []\n",
    "    for word, pos in zip(sentence_ws, sentence_pos):\n",
    "        is_Na_or_V_or_A_or_D = pos.startswith(\"Na\") or pos.startswith(\"V\") or pos.startswith(\"A\")\n",
    "        if is_Na_or_V_or_A_or_D and len(word) > 1:\n",
    "            cleaned.append(word)\n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "# Word segmentation\n",
    "def word_segmentation(contents, ws_driver, pos_driver, ner_driver):\n",
    "    '''\n",
    "    - contents: 一個 list，每個元素是一篇文章的全文內容\n",
    "    - ws: 斷詞模型\n",
    "    '''\n",
    "    ws_results = ws_driver(contents)\n",
    "    pos_results = pos_driver(ws_results)\n",
    "    contents_cleaned = []\n",
    "    for sentence, sentence_ws, sentence_pos in zip(contents, ws_results, pos_results):\n",
    "        sentence_cleaned = clean(sentence_ws, sentence_pos)\n",
    "        contents_cleaned.append(sentence_cleaned)\n",
    "\n",
    "    return contents_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_news = pd.read_csv('../data/news_filtered_merged.csv')\n",
    "contents = data_news['content'].tolist()\n",
    "contents_cleaned = word_segmentation(contents, ws, pos, ner)\n",
    "# add the cleaned content back to the dataframe as a column named 'content_cleaned'\n",
    "data_news['content_cleaned'] = contents_cleaned\n",
    "data_news.to_csv('../data/news_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate cleaned data and save\n",
    "def generate_cleaned_data(name, data, ws, pos, ner):\n",
    "    contents = data['content'].tolist()\n",
    "    contents_cleaned = word_segmentation(contents, ws, pos, ner)\n",
    "    data['content_cleaned'] = contents_cleaned\n",
    "    data.to_csv(f'../data/{name}_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate cleaned data for ptt and dcard\n",
    "data_ptt = pd.read_csv('../data/ptt_filtered_labeled.csv')\n",
    "data_dcard = pd.read_csv('../data/dcard_filtered_labeled.csv')\n",
    "data_to_clean = {'ptt': data_ptt, 'dcard': data_dcard}\n",
    "for name, data in data_to_clean.items():\n",
    "    generate_cleaned_data(name, data, ws, pos, ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from scipy import sparse\n",
    "\n",
    "# parameters \n",
    "n_features = {'ptt': 10, 'dcard': 10, 'news': 10, 'all': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(source, data, n_features, days_ahead):\n",
    "    '''\n",
    "    - source: the source of the data\n",
    "    - data: a pandas dataframe with a column named 'content_cleaned'\n",
    "    - n_features: the number of features to select\n",
    "    - days_ahead: the number of days ahead to predict\n",
    "    '''\n",
    "    # Drop the rows where label = -1\n",
    "    data = data[data['label_day'+str(days_ahead)] != -1]\n",
    "    # TF-IDF\n",
    "    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, ngram_range=(1, 3))\n",
    "    X = vectorizer.fit_transform(data['content_cleaned'])\n",
    "    # select the top 1000 features\n",
    "    ch2 = SelectKBest(chi2, k=min(n_features[source],X.shape[1] - 30)) \n",
    "    X = ch2.fit_transform(X, data['label_day'+str(days_ahead)])\n",
    "    # get the target variable\n",
    "    y = data['label_day'+str(days_ahead)]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Model Training for All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "# initialize all parameters\n",
    "params = {\n",
    "    'Naive Bayes': {},\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1],\n",
    "        #'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['scale'],\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(source, data, n_features, days_ahead, backtest=False, period = -1):\n",
    "    '''\n",
    "    - source: the source of the data\n",
    "    - data: a pandas dataframe with a column named 'content_cleaned'\n",
    "    - n_features: the number of features to select\n",
    "    - days_ahead: the number of days ahead to predict\n",
    "    '''\n",
    "    result = {}\n",
    "    # feature extraction\n",
    "    X, y = feature_extraction(source, data, n_features, days_ahead)\n",
    "    # densify the sparse matrix\n",
    "    X = X.toarray()\n",
    "    # split the data into training and testing sets\n",
    "    if backtest:\n",
    "        # 因為後面有照日期排序，所以這邊可以照順序分出 test 和 train(上一個方啊會報錯)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    # kfold\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    models = {\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'Random Forest': RandomForestClassifier(),\n",
    "        'SVM': SVC(),\n",
    "        'XGBoost': XGBClassifier()\n",
    "    }\n",
    "    # search for the optimal parameters for each model by grid search\n",
    "    best_models = {}\n",
    "    for model_name, model in models.items():\n",
    "        grid_search = GridSearchCV(model, params[model_name], cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "    # stack the models\n",
    "    stack = StackingClassifier(estimators=[(name, model) for name, model in best_models.items()], final_estimator=LogisticRegression())\n",
    "    stack.fit(X_train, y_train)\n",
    "    # predict the test set and calculate the accuracy and confusion matrix, and save the results\n",
    "    # best_models (respectively)\n",
    "    for name, model in best_models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        confusion = confusion_matrix(y_test, y_pred)\n",
    "        result[name] = {'accuracy': accuracy, 'confusion': confusion, 'prediction': y_pred}\n",
    "    # stack\n",
    "    y_pred = stack.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    result['stack'] = {'accuracy': accuracy, 'confusion': confusion, 'prediction': y_pred}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for ptt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:42<00:00,  8.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for dcard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:52<00:00, 10.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for news\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:19<00:00, 15.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "datas = {\n",
    "    'ptt': pd.read_csv('../data/ptt_cleaned.csv'),\n",
    "    'dcard': pd.read_csv('../data/dcard_cleaned.csv'),\n",
    "    'news': pd.read_csv('../data/news_cleaned.csv'),\n",
    "}\n",
    "# Train the models for each source media and get the results\n",
    "results = {}\n",
    "for name, data in datas.items():\n",
    "    # drop nan for content_cleaned\n",
    "    data = data.dropna(subset=['content_cleaned'])\n",
    "    print(f'Training models for {name}')\n",
    "    results[name] = {}\n",
    "    for days_ahead in tqdm.tqdm(range(1, 6)):\n",
    "        results[name][days_ahead] = train(name, data, n_features, days_ahead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the results\n",
    "results_flat = {}\n",
    "for name, result in results.items():\n",
    "    for days_ahead, models in result.items():\n",
    "        for model_name, model_result in models.items():\n",
    "            result_name = f'{name}_{days_ahead}_{model_name}'\n",
    "            results_flat[result_name] = model_result\n",
    "\n",
    "# save the flattened results\n",
    "results_df = pd.DataFrame(results_flat).T\n",
    "results_df.to_csv('../data/prob2_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "results_df\n",
    "results_df.to_csv('../data/prob2_sorted_f10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(source, data, period):\n",
    "    '''\n",
    "    - source: the source of the data (news, ptt, dcard)\n",
    "    - data: a pandas dataframe with a column named 'content_cleaned'\n",
    "    - period: the number of days to backtest\n",
    "    '''\n",
    "    data.loc[:, 'date'] = pd.to_datetime(data['date'])\n",
    "    data = data.sort_values(by='date')\n",
    "    result = {} # key is the period, value is the accuracy and confusion matrix of the best model\n",
    "    start_date = data['date'].min()\n",
    "    \n",
    "    while start_date + pd.Timedelta(days=int(period*0.2) - 1) <= data['date'].max():\n",
    "        end_date = start_date + pd.Timedelta(days=period - 1)\n",
    "        period_data = data[(data['date'] >= start_date) & (data['date'] <= end_date)]\n",
    "        date_interval = f'{start_date.strftime(\"%Y-%m-%d\")}_{end_date.strftime(\"%Y-%m-%d\")}'\n",
    "        result[date_interval] = {}\n",
    "        for days_ahead in range(1, 6):\n",
    "            result_name = f'day_{days_ahead}'\n",
    "            result[date_interval][result_name] = train(source, period_data, n_features, days_ahead, backtest=True, period=period)\n",
    "        start_date = start_date + pd.Timedelta(days=int(period*0.2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for ptt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 199, in fit\n    y = self._validate_targets(y)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 747, in _validate_targets\n    raise ValueError(\nValueError: The number of classes has to be greater than one; got 1 class\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining models for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m results_backtest[name] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 15\u001b[0m results_backtest[name] \u001b[38;5;241m=\u001b[39m backtest(name, data, \u001b[38;5;241m90\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_backtest[name])\n",
      "Cell \u001b[0;32mIn[48], line 19\u001b[0m, in \u001b[0;36mbacktest\u001b[0;34m(source, data, period)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m days_ahead \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[1;32m     18\u001b[0m         result_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdays_ahead\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 19\u001b[0m         result[date_interval][result_name] \u001b[38;5;241m=\u001b[39m train(source, period_data, n_features, days_ahead, backtest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, period\u001b[38;5;241m=\u001b[39mperiod)\n\u001b[1;32m     20\u001b[0m     start_date \u001b[38;5;241m=\u001b[39m start_date \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(period\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.2\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(source, data, n_features, days_ahead, backtest, period)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     29\u001b[0m     grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(model, params[model_name], cv\u001b[38;5;241m=\u001b[39mkfold, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m     grid_search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     31\u001b[0m     best_models[model_name] \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# stack the models\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m _warn_or_raise_about_fit_failures(out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_score)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 199, in fit\n    y = self._validate_targets(y)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/chengliang/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py\", line 747, in _validate_targets\n    raise ValueError(\nValueError: The number of classes has to be greater than one; got 1 class\n"
     ]
    }
   ],
   "source": [
    "datas = {\n",
    "    'ptt': pd.read_csv('../data/ptt_cleaned.csv'),\n",
    "    'dcard': pd.read_csv('../data/dcard_cleaned.csv'),\n",
    "    'news': pd.read_csv('../data/news_cleaned.csv'),\n",
    "}\n",
    "# Train the models for each source media and get the results\n",
    "results_backtest = {}\n",
    "# 初始化混淆矩陣\n",
    "total_conf_matrix = np.zeros((2, 2))\n",
    "for name, data in datas.items():\n",
    "    # drop nan for content_cleaned\n",
    "    data = data.dropna(subset=['content_cleaned'])\n",
    "    print(f'Training models for {name}')\n",
    "    results_backtest[name] = {}\n",
    "    results_backtest[name] = backtest(name, data, 90)\n",
    "    print(results_backtest[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the results\n",
    "results_backtest_flat = {}\n",
    "total_confusion_matrix = {}\n",
    "total_accuracy = {}\n",
    "\n",
    "# 初始化 total confusion matrix\n",
    "for name, result in results_backtest.items():\n",
    "    total_confusion_matrix[name] = {}\n",
    "    total_accuracy[name] = {}\n",
    "    for date_interval, days_ahead in result.items():\n",
    "        for day_ahead, model in days_ahead.items():\n",
    "            total_confusion_matrix[name][day_ahead] = {}\n",
    "            total_accuracy[name][day_ahead] = {}\n",
    "            for model_name, model_result in model.items():\n",
    "                total_confusion_matrix[name][day_ahead][model_name] = np.zeros((2, 2))\n",
    "                total_accuracy[name][day_ahead][model_name] = 0\n",
    "\n",
    "for name, result in results_backtest.items():\n",
    "    for date_interval, days_ahead in result.items():\n",
    "        for day_ahead, model in days_ahead.items():\n",
    "            for model_name, model_result in model.items():\n",
    "                #計算total confusion matrix\n",
    "                total_confusion_matrix[name][day_ahead][model_name] += model_result[\"confusion\"]\n",
    "                total_accuracy[name][day_ahead][model_name] += model_result[\"accuracy\"]\n",
    "\n",
    "for name, result in results_backtest.items():\n",
    "    for date_interval, days_ahead in result.items():\n",
    "        for day_ahead, model in days_ahead.items():\n",
    "            for model_name, model_result in model.items():\n",
    "                result_name = f'{name}_{day_ahead}_{model_name}'\n",
    "                total_acc_conf = {\"accuracy\": total_accuracy[name][day_ahead][model_name],\"confusion_matrix\": total_confusion_matrix[name][day_ahead][model_name]}\n",
    "                results_backtest_flat[result_name] = total_acc_conf\n",
    "\n",
    "# save the flattened results\n",
    "results_df = pd.DataFrame(results_backtest_flat).T\n",
    "results_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "results_df.to_csv('../data/results/backtest_result.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相比 新興 債券 面臨 悲觀 預期 認為 新興 上漲 空間 抵擋 貨幣 縮減 政策 通膨 觸頂 原物料 出口 有利 財務 狀況 新興 國家 看好 標的 新興 主權 債券 需要 選擇性 投資 主動式 投資 機會 超越 指數 表現 特別 看好 投資 主題 原物料 商品 旅遊業 相對 落後 國家 主題 國家 債券 殖利率 債券 利差 約為 基本點 疫情 擴大 基本點 具有 吸引力 相較 投資級 債券 利差 疫情 水平 相近 約為 基本點 利差 收歛 收斂 空間 原物料 商品 價格 走高 相關 出口國 可望 受惠 出口 綠色 轉型 金屬 國家 計畫 布局 標的 綠色 轉型 過程 石油 基礎 設施 投資 不足 意味 綠色 能源 接手 石油 價格 維持 高檔 石油 出口國 吸引力 國家 出現 巨額 財政 赤字 疫情 惡化 盈餘 現金 用來 支撐 經濟 認為 投資 石油 出口國 支持 綠色 轉型 目標 衝突 遠離 排放 長期 趨勢 實現 石油 出口國 利用 債券 收益 確保 發展 主題 旅遊業 國家 收入 疫情 封鎖 期間 出現 下滑 疫苗 接種 檢測 技術 改進 旅人 回歸 旅遊業 回升 時間 問題 方式 旅遊 收入 增加 事實 國家 看到 相關 跡象 萌芽 國家 承受 病毒 肆虐 密切 關注 資源 不足 疫苗 接種 經濟 重啟 方面 進展 緩慢 國家 沙漠 國家 疫苗 接種率 相信 基本面 改善 國家 迎頭趕上 創造 良好 投資 機會\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/news_filtered_merged.csv')\n",
    "contents = data['content'].tolist()\n",
    "contents_cleaned = word_segmentation(contents[:100], ws, pos, ner)\n",
    "print(contents_cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['教學', '奈米 韭菜 這樣 站上 大關 小弟 成本 獲利 高\\n\\n 除息 知道 填息 賣掉 獲利 股息\\n\\n\\n\\n 小弟 知道 謝謝', nan, '通報 文章 想法 來去 看看', '除息稅 除息 差\\n 看跌', '機會 準備 位數', '刪除 內容 一樣 錯過 相見', '文章 分析 基本面 預測 參考', '高歌 離席', '參加', '成本', '關注 航運 報價 營收 營收 準備 營收 公布', '權息', '刪除 內容 一樣 錯過 相見', '你我 持續 大膽 加碼', '傾向 賣掉 疫情 結果 實現 收益 收益 股息 賣掉去 殖利率 標的', nan, '停利 目標 區間 開始 波段 倉位 停利 動作 預計 停利 出場 嘗試 摸頭 收盤 十日線 作為 停利 標準 方法 擇時 交易 實際 時間 成本 操作 策略 保持 長期 操作 倉位 原文 停止 操作 條件 達成 停下 開始 使用 股票 研究 報告 出來 發文 發文 發現 持有 投資 充滿 絕望 決定 分享出來 股票 操作 感到 手足無措 出來 分享 兼顧 身心健康 大錢', '這樣 啦\\n 攤到 繼續 機會', '賣掉 想說 低檔 接回 噴到 時機 難過']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_news = pd.read_csv('../data/dcard_cleaned.csv')\n",
    "contents_news = df_news['content_cleaned'].tolist()\n",
    "print(contents_news[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_day3\n",
       "-1.0    2724\n",
       " 0.0    2594\n",
       " 1.0    1343\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas['dcard']['label_day3'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
