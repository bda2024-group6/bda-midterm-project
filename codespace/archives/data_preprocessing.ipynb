{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "對新聞、討論的文章進行資料前處理，包含斷詞、去除標點符號、計算 tf-idf、特徵選取等等，以利後續的模型訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入 CKIP Tagger 的相關函數\n",
    "\n",
    "若要使用 CKIP Tagger 進行斷詞，需要先安裝 CKIP Tagger 的 Python 套件，並且載入相關函數。\n",
    "\n",
    "請參考 https://github.com/ckiplab/ckiptagger 的說明，安裝 CKIP Tagger 的 Python 套件。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "2024-04-14 14:53:17.514234: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ckiptagger/model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    }
   ],
   "source": [
    "# 先把我們需要的函數載入\n",
    "ws = WS(\"./data_ckip\") # 斷詞\n",
    "pos = POS(\"./data_ckip\") # 詞性標注\n",
    "ner = NER(\"./data_ckip\") # 命名實體識別 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_segmentation(contents, ws):\n",
    "    word_sentence_list = ws(contents, \n",
    "                        sentence_segmentation=True,\n",
    "                        segment_delimiter_set={'?', '？', '!', '！', '。', ',','，', ';', ':', '、', ' ', '.'})\n",
    "    # 標點符號\n",
    "    punc = ['，', '。', '、', '：', '；', '？', '！', '「', '」', '（', '）', '『', '』', '—', '－', '～', '…', '‧', '《', '》', '〈', '〉', '﹏﹏']\n",
    "    eng_punc = [',', '.', ':', ';', '?', '!', '(', ')', '[', ']', '&', '@', '#', '$', '%', '-', '_', '*', '/', '\\\\', '+', '=', '>', '<', '\"', \"'\", '’', '‘', '“', '”', ' ']\n",
    "    # 停用詞\n",
    "    stop_words = ['全文', '日', '月', '年', 'br', '中央社', '公司', '上午', '下午', '日期']\n",
    "\n",
    "    word_sentence_list = [[word for word in sentence if not any(char.isdigit() for char in word)] for sentence in word_sentence_list]\n",
    "    word_sentence_list = [[word for word in sentence if word not in punc] for sentence in word_sentence_list]\n",
    "    word_sentence_list = [[word for word in sentence if word not in eng_punc] for sentence in word_sentence_list]\n",
    "    word_sentence_list = [[word for word in sentence if word not in stop_words] for sentence in word_sentence_list]\n",
    "\n",
    "    return word_sentence_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, days, ws):\n",
    "    df = df[df['label_day' + str(days)] != -1] # 把標籤為 -1 的 row 全部移除\n",
    "    Y = lambda df, days: df['label_day' + str(days)].tolist() # 提取標籤\n",
    "    contents = df['content'].tolist() # 提取正文內容\n",
    "    # 對正文內容進行斷詞\n",
    "    word_sentence_list = word_segmentation(contents, ws)\n",
    "    # 取得 1-gram - 3-gram 的 tf-idf 特徵\n",
    "    tv = TfidfVectorizer(ngram_range=(1, 3))\n",
    "    tfidf = tv.fit_transform([' '.join(sentence) for sentence in word_sentence_list])\n",
    "    # 取得前 1000 個特徵\n",
    "    ch2 = SelectKBest(chi2, k=1000)\n",
    "    X = ch2.fit_transform(tfidf, Y(df, days))\n",
    "    # 將 foreign_investor_surplus, investment_trust_surplus, dealer_surplus 加入到 X\n",
    "    X = sparse.hstack((X, sparse.csr_matrix(df[['foreign_investor_surplus', 'investment_trust_surplus', 'dealer_surplus']])))\n",
    "    return X, Y(df, days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4890, 1003)\n",
      "4890\n"
     ]
    }
   ],
   "source": [
    "df_news = pd.read_csv('../data/news_filtered_merged.csv') # 讀取新聞資料\n",
    "X, Y = preprocessing(df_news, 1, ws) # 對新聞資料進行前處理\n",
    "print(X.shape) # (新聞數, 特徵數)\n",
    "print(len(Y)) # 標籤數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_day1\n",
       "1.0    2639\n",
       "0.0    2251\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/news_filtered_merged.csv')\n",
    "df = df[df['label_day1'] != -1]\n",
    "df.head()\n",
    "df['label_day1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X and Y\n",
    "sparse.save_npz('../data/X.npz', X)\n",
    "sparse.save_npz('../data/Y.npz', sparse.csr_matrix(Y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
